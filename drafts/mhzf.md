Unsupervised multi-objective rationality
(The multi-hazelflax)

(Prerequisite: Unsupervised Rationality)

Suppose we want model other agents as perfectly ratioal (without an infinite regress when they try to simulate each other).  I.e. rather the a hypothetical universe predicting their code, it predicts their utility function.
Suppose all agents can agree on a `prior`, and a way of choosing an equilibrium.
The set of universes (the domain of the `prior`) gives the set of all potential `agent`s and their utility functions.
For a given set of policies (each corresponding to a utility function) we can calculate the expected value of each utility function (by expanding each universe to a block (given the set of policies) and calculating each utility.

(This essentially compresses the game matrix into a form where consensus may be more fesableib. (While also modeling uncertanty about payoffs and which agents exist.))

What this entails is that each agent would do the exact same calculation to arrive at a set of optimum policies (covering all potential agents (and observations)) (by computing the game matrix and selecting an equilibrium), then lookup a policy (corresponding to their utility function) and run it on their observations to find out what to do.

If the choice of equilibrium essentially facilitates coordination between policies (such that it doesnâ€™t matter if agents with the same or similar utility share a policy), the formula can be simplified so the {utility: value} map is computed from an {(observations, utility): choice} map.  
(If this were approximated, everyone would need to approximate it in the same way (your choices might not be so good if other agents make choices you aren't counting on). The problem with different approximations is that the differences aren't modeled, so the (apparently) optimal policy may be brittle.  (This is why the original Hazelflax models other agent's code rather than their objectives.))

Maybe if people agree on an sufficiently constrained `prior` this would be tractable, and facilitate tight coordination (while taking account of uncertainty).  It could be like a generalization of the idea of a blockchain.

(This doesn't quite answer the question of whether mutual rationality is possible ...)
